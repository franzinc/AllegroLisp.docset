<html><head><meta name="viewport" content="width=device-width, initial-scale=1"> <meta http-equiv="content-type" content="text/html; charset=UTF-8"> <link rel="stylesheet" href="acldoc-styles.css" type="text/css"><title>Symmetric Multiprocessing in Allegro CL</title></head><body><table border="0" width="100%" cellpadding="1" cellspacing="0"><tr><td colspan="2" bgcolor="#00FFFF"><table border="0" cellpadding="5" cellspacing="3"><tr><td align="left" bgcolor="#00FFFF"><a href="contents.htm"><b>ToC</b></a></td><td align="left" bgcolor="#00FFFF"><a href="introduction.htm"><b>DocOverview</b></a></td><td align="left" bgcolor="#00FFFF"><a href="cgide.htm"><b>CGDoc</b></a></td><td align="left" bgcolor="#00FFFF"><a href="release-notes.htm"><b>RelNotes</b></a></td><td align="left" bgcolor="#00FFFF"><a href="http://www.franz.com/support/faq/"><b>FAQ</b></a></td><td align="left" bgcolor="#00FFFF"><a href="index.htm"><b>Index</b></a></td><td align="left" bgcolor="#00FFFF"><a href="permuted-index.htm"><b>PermutedIndex</b></a></td></tr></table></td><td align="right"><b>Allegro CL version 10.1</b><br><small><a href="introduction.htm#updates-s">Unrevised from 10.0 to 10.1.</a></small><br><a href="http://www.franz.com/support/documentation/10.0/doc/smp.htm">10.0 version</a></td></tr></table><h1 id="2">Symmetric Multiprocessing in Allegro CL</h1><p id="3">This document contains the following sections:</p><a href="#smp-intro-1">1.0 Symmetric Multiprocessing introduction</a><br>&nbsp;&nbsp;&nbsp;<a href="#smp-require-2">1.1 Loading smp-related functionality</a><br>&nbsp;&nbsp;&nbsp;<a href="#smp-example-2">1.2 An example of the difference between SMP Lisp and non-SMP Lisp</a><br>&nbsp;&nbsp;&nbsp;<a href="#non-smp-avail-2">1.3 Non-SMP images on platforms that support SMP</a><br><a href="#depr-macs-1">2.0 Deprecated macros</a><br>&nbsp;&nbsp;&nbsp;<a href="#atomically-2">2.1 Deprecated macro: excl::atomically</a><br>&nbsp;&nbsp;&nbsp;<a href="#without-interrupts-2">2.2 Deprecated macro: without-interrupts</a><br>&nbsp;&nbsp;&nbsp;<a href="#without-scheduling-2">2.3 Deprecated macro: sys:without-scheduling</a><br><a href="#new-macs-1">3.0 New macros and related functionality</a><br>&nbsp;&nbsp;&nbsp;<a href="#non-sync-2">3.1 Non-synchronizing usages</a><br>&nbsp;&nbsp;&nbsp;<a href="#read-write-2">3.2 Atomic read-modify-write primitives</a><br>&nbsp;&nbsp;&nbsp;<a href="#concur-2">3.3 Concurrency control for shared objects</a><br>&nbsp;&nbsp;&nbsp;<a href="#sharable-locks-2">3.4 Sharable locks</a><br>&nbsp;&nbsp;&nbsp;<a href="#barrier-api-2">3.5 The barrier API</a><br>&nbsp;&nbsp;&nbsp;<a href="#queue-2">3.6 Queues</a><br>&nbsp;&nbsp;&nbsp;<a href="#condition-vars-2">3.7 Condition Variables</a><br><a href="#safe-ops-1">4.0 Safe and unsafe operators</a><br>&nbsp;&nbsp;&nbsp;<a href="#general-lisp-unsafe-2">4.1 Unsafe standard Lisp operations: *features*, *modules*, require/provide, external-format loading, etc.</a><br>&nbsp;&nbsp;&nbsp;<a href="#smp-mop-2">4.2 SMP and the MOP</a><br>&nbsp;&nbsp;&nbsp;<a href="#suspend-all-2">4.3 Suspending all processes</a><br><a href="#non-smp-1">5.0 Ensuring code is not loaded into an SMP Lisp</a><br><a href="#memlog-1">6.0 Memlog: A Facility for Minimally Intrusive Monitoring             of Complex Application Behavior</a><br><hr><hr><h2 id="4"><a name="smp-intro-1">1.0 Symmetric Multiprocessing introduction</a></h2>

<p id="5">
This   document   describes   the  Symmetric   Multiprocessing   (SMP)
implementation  in   Allegro  CL   on  certain  platforms.   See  also
the  <a href="multiprocessing.htm">multiprocessing.htm</a> document,  which describes
the  older  Lisp-based uniprocessor  implementation  but  most of  the
functionality applies to SMP as well.
</p>
<p id="6">
Starting in Allegro CL 9.0, Allegro CL on certain platforms will have
images that will allow using multiple independent processors. This may
result in dramatic speedups in applications as the additional
processor resources are used. There is also a separate non-SMP
distribution which, like earlier versions of Allegro CL, runs on one
hardware processor only.
</p>
<p id="7">
Note that the SMP version works on a machine that has only one
processor and using the SMP version may be more efficient on such
machines even though (obviously) only one process can run at a time.
</p>
<p id="8">
But there is a downside. Using multiple processors simultaneously can
make programs that run correctly on a single processor fail, either by
producing incorrect results or by signaling unexpected errors or even
by failing altogether. Here are three areas where such failures can
occur:
</p>
<ol>
<li id="9">
There is no automatic way to make code being executed in one process
run to completion while all other processes do nothing. In a Lisp
using one processor only to execute Lisp code, wrapping a section of
code with <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>
meant that when that code was run, it would run to completion while
all other processes waited. Using multiple processors means that other
processes run at the same time. (The code will still not process
interrupts, but that no longer means other Lisp code is not running.)
See <a href="#smp-example-2">Section 1.2 An example of the difference between SMP Lisp and non-SMP Lisp</a> for more information
on this point.
</li>
<li id="10">
When an object is modified by one process and simultaneously accessed
by another, the accessing process can get an incorrect result or can
even fail, perhaps causing Lisp itself to fail. By 'incorrect result'
we do not just mean an out of date result; we mean there is a
possibility of getting a result that was never
correct. See <a href="#safe-ops-1">Section 4.0 Safe and unsafe operators</a> for more
information.
</li>
<li id="11">
Certain operators that are supposed to guarantee certain results can
no longer be guaranteed to work as advertised. <a href="../ansicl/dictentr/pushnew.htm"><b>pushnew</b></a>, for example, if called without some
process-locking protection in two separate processes, can push the
same value onto a list from each process resulting in a duplicate in
the list. (Each process completes the test for whether the object is
new before the other has added the item to the list, and so each then
adds the item.)
</li>
</ol>
<p id="12">
Some of these problems (but not number 1 so long as the Lisp heap was
not modified by foreign code) actually already exist in a non-SMP
multiprocessing Lisp, as Allegro CL has been for many years. But
because the system-initiated process-switch latency was so slow (on
the order of a second) compared to the execution speed, the errors
either never occurred or were so rare that the problem was never
properly identified or even noticed. But in an SMP Lisp, where
processes are just running simultaneously and there is no system
process switch latency, the rare or never happening events are
suddenly much, much more likely and subtle coding errors which could
be ignored before become unignorable.
</p>
<p id="13">
Please realize first that essentially all problems arise from object
modification, although the failure can come from the process reading a
value (because the modification process can result in
inconsistencies); and second that tools such as locks
(see <a href="multiprocessing.htm#process-locks-1">Process
locks</a> in <a href="multiprocessing.htm">multiprocessing.htm</a>) and gates
(see <a href="multiprocessing.htm#gates-1">Gates</a>
in <a href="multiprocessing.htm">multiprocessing.htm</a>) are available to ensure
that processes do not interfere with each other. If you use SMP, it is
your programs responsibility to ensure that modifications are
consistent and do not cause problems.
</p>
<p id="14">
The important point is that programs which ran without error (or had
such a small chance of error that they for all practical purposes ran
without error) may fail in an SMP environment, either because of
mysterious and unexpected errors or (and this is likely worse) by not
signaling an error and instead producing very incorrect results.
<p id="15">
</p>
This document describes the problems and also the new tools which will
assist in making your program SMP-safe.  It discusses the general
problem and the macros and data elements introduced in Allegro CL 9.0
to control concurrent access. Many of the macros have keyword
arguments that can be used to control how the macro expands in a
non-SMP Lisp. This makes it easier to write source code that works
efficiently whether it is compiled for running in an SMP Lisp or a
non-SMP Lisp.
</p>
<p id="16">
In a non-SMP Lisp only one thread of control at a time is ever
running Lisp code. Lisp execution is gated by a mutex
and low-level runtime code selects one lisp process to execute at a time.
A Lisp process can voluntarily yield control, either explicitly
or by waiting on some event. A running Lisp process can also be
preempted, temporarily ceding control to another process in response
to some event.
</p>
<p id="17">
In a non-SMP Lisp interleaved execution of multiple processes is
coarse-grained. A process can not lose control at arbitrary points
in its execution. Running Lisp code checks periodically, at what might
be called safe points, to see if an interruption in the normal flow of
sequence has been requested. If so, the state of the running process
is saved, the state of the preempting process restored, and that second
process allowed to execute.
</p>
<p id="18">
Lisp-level handling of asynchronous signals is restricted to happen at
these same safe points. This is true in SMP-enabled Lisps as well as
in non-SMP Lisps. Low-level, non-Lisp support code keeps a record
of signals seen but not yet processed. This code responds to asynchronous
signals like SIGALRM by recording the event in an unprocessed-signals
buffer and setting a global flag to show that a signal has been seen,
and then returning to the lisp processing that was happening when
the signal was recognized. At the next safe point, the state of the global
flag will be seen and Lisp-level processing of the signal will occur.
In a non-SMP Lisp this could result in a process switch.
</p>
<p id="19">
In a non-SMP Lisp, controlling concurrent access to shared objects
often reduces to controlling when these process-switch and
signal-handling events can occur. By ensuring that a block of Lisp
code will execute without interruption, an application running in a
non-SMP Lisp can provide arbitrarily complex operations that will look
atomic to multiple processes. This is obviously inadequate in an SMP
Lisp, where multiple threads of control are running Lisp code
simultaneously.
</p>

<hr><h2 id="20"><a name="smp-require-2">1.1 Loading smp-related functionality</a></h2>

<p id="21">
Most symbols naming SMP functionality are in
the <code>multiprocessing</code>
(nickname <code>mp</code>) package or in
the <code>excl</code> package. Some functionality is loaded into
all images and other is in the <code>:smputil</code> module. You
should load this module with a form like
</p>
<pre id="22">
(eval-when (compile load eval) (require :smputil))
</pre>

<p id="23">
(Just <code>(require :smputil)</code> is sufficient when typed
to the top-level.)
</p>



<hr><h2 id="24"><a name="smp-example-2">1.2 An example of the difference between SMP Lisp and non-SMP Lisp</a></h2>


<p id="25">
Consider the following example. We have a variable VAR whose initial
value is the fixnum 8. Various processes are running in Lisp and
independently incrementing or decrementing the value of VAR with calls
to <a href="../ansicl/dictentr/incfdecf.htm"><b>incf</b></a> and <a href="../ansicl/dictentr/incfdecf.htm"><b>decf</b></a>. Our first attempt is:
</p>

<pre id="26">
;; In process-1:
(incf var)

;; In process-2:
(incf var)

;; In process-3:
(decf var)
</pre>

<p id="27">
But this might cause us trouble, because <code>(incf var)</code>
macroexpands to <code>(setq var (+ var 1))</code>. It is
possible that <code>(+ 1 var)</code> is evaluated and then there
is a process switch, before that value is stored as the value of VAR,
so when the process gets control again, it might store what has become
the wrong value.
</p>
<p id="28">
But in a non-SMP Lisp, we can prevent a process switch
with <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>, so
we recode as follows:
</p>

<pre id="29">
;; In process-1:
(without-interrupts (incf var))

;; In process-2:
(without-interrupts (incf var))

;; In process-3:
(without-interrupts (decf var))
</pre>

<p id="30">
In non-SMP Lisp, once process-1, process-2, and process-3 have
completed (or at least executed the forms shown), the value of VAR
will be 9 (8 + 1 + 1 - 1). We do not actually know in what order the
additions and subtraction will occur, but the <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> guarantees that each will
complete once it has started without any process switch and so we can
be confident of the final result.
</p>
<p id="31">
In an SMP Lisp, the <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> macro does not have the
effect of preventing a process switch because all processes can be
running simultaneously on different processors, and so the whole
notion of 'process switch' is problematic. So the following can
happen:
</p>

<pre id="32">
1. process-1 reads the value 8 from VAR and places that value in one
of its registers.

2. Before process-1 does its calculation and stores a new value in
VAR, process-2 reads the value (still 8) from VAR and places it in one
of its registers.

3. process-1 adds 1 to 8 and stores the result (9) in VAR.

4. After process-1 stores its new value but before process-2 stores a
new value, process-3 reads the value (9) from VAR and places it in one
of its registers.

5. process-2 adds 1 to 8 and stores the result (9) as the value of
VAR.

6. process-3 subtracts 1 from 9 and stores the result (8) as the value
of VAR.
</pre>

<p id="33">
When all this completes, the value of VAR is 8, not 9. The value could
indeed end up as 7 (process-3 reads first and stores last), 8 (as
shown), 9 or 10 (left as an exercise to the reader).
</p>
<p id="34">
So code which depended on <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> to ensure that certain
operations will not be interfered with and that therefore certain
final results could be depended upon will no longer work as expected.
</p>
<p id="35">
The fundamental issue is that on a non-SMP Lisp, process locking
(ensuring that code in a single Lisp process is guaranteed to execute
to completion without interruption) gave you object locking (ensuring
that only one process could read or set a value) as a side effect. In
an SMP Lisp, that is no longer true.
</p>
<p id="36">
New macros (see <a href="#new-macs-1">Section 3.0 New macros and related functionality</a>) provide
object locking to allow the example here and related examples to run
as desired. The macros <a href="operators/excl/incf-atomic.htm"><b>incf-atomic</b></a> and <a href="operators/excl/decf-atomic.htm"><b>decf-atomic</b></a> are specific to this example and
others to related examples. Of course, programmers can also use more
complex mechanisms to lock objects and processes and avoid undesired
concurrency, although these techniques often have a significant
overhead.
</p>
<p id="37">
Here is the code that guarantees that all the incf's and decf's will
run as desired (but in an undefined order). This works in SMP and
non-SMP Lisps.
</p>
<pre id="38">
;; In process-1:
(incf-atomic var)

;; In process-2:
(incf-atomic var)

;; In process-3:
(decf-atomic var)
</pre>



<hr><h2 id="39"><a name="non-smp-avail-2">1.3 Non-SMP images on platforms that support SMP</a></h2>

<p id="40">
All platforms that will support SMP Lisp will also have non-SMP images
available. Current programs that depend on the fact that Lisp code is
run on a single processors will thus continue to work using the
non-SMP images without any changes relating to SMP (beyond trivial
suppression of compiler warnings, done by evaluating <code>(setq
excl::*warn-smp-usage* nil)</code>).
</p>
<p id="41">
Therefore there is no need for users who do not wish to use SMP to
make any changes to their programs. The rest of this document is
directed at users who do wish to use SMP. They will have to determine
whether their code must be modified (usually, some changes must be
made) using the information in this document.
</p>




<hr><hr><h2 id="42"><a name="depr-macs-1">2.0 Deprecated macros</a></h2>

<p id="43">
Three macros are used in non-SMP Lisps to provide concurrency control:
<b>excl::atomically</b>, <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>, and
<a href="operators/system/without-scheduling.htm"><b>without-scheduling</b></a>. (The
symbol <b>excl::atomically</b> was not exported and the associated
macro never documented, but some users were aware of it; if you are
unfamiliar with <b>excl::atomically</b>, you need not worry about it
as its use is now deprecated. You just have less code to modify). 
</p>
<p id="44">
These macros are all very light-weight in processing overhead and are
much cheaper than using a process-lock. They have the additional
advantage that they do not require the multiprocessing package be
loaded. This allows a programmer to write code that runs correctly in
a multi-process application, but still runs efficiently in a
single-process application. All three rely on the coarse-grained
scheduling of non-SMP multiprocessing. All three represent problem
situations for multiprocessing under SMP. They are all deprecated in 8.2
and later Lisps, although they are still available and still perform
the same functions in a non-SMP lisp as they did before 8.2.
</p>


<p id="45">
New macros provide the same functions as the deprecated macros, in
ways that are compatible with an smp environment. The new macros are
described in <a href="#new-macs-1">Section 3.0 New macros and related functionality</a>. The deprecated
macros generate compile-time warnings (which can be globally muffled
by evaluating <code>(setq excl::*warn-smp-usage* nil)</code>).
</p>


<hr><h2 id="46"><a name="atomically-2">2.1 Deprecated macro: excl::atomically</a></h2>

<p id="47">
The <b>excl::atomically</b> macro was never documented and the symbol
naming it was never exported. However, some users made use of
it. Users who never used atomically can skip this section.
</p>
<p id="48">
<b>excl::atomically</b> is wrapped around a sequence of forms:
</p>

<pre id="49">
(excl::atomically . BODY)
</pre>

<p id="50">
This acted exactly like
</p>

<pre id="51">
(progn . BODY)
</pre>

<p id="52">
as far as code generation was concerned, but the compiler would produce
a diagnostic if BODY involved any operations that might result in a
process switch or a garbage collection. Such opportunities are inherent
in almost any out-of-line call, in object allocation, in anything that
might signal an error, and in several other low-level actions. If BODY
contained none of these, then the compiler would accept the form and the
programmer could be confident that BODY would execute atomically as far
as Lisp processes were concerned.
</p>
<p id="53">
A major use of <b>excl::atomically</b> was to wrap a section of code
in which it was required that garbage collection not relocate some
object or objects. This requirement was independent of
multiprocessing concerns, and happened most often in low level code
that was trying to process an array's elements very efficiently.
</p>
<p id="54">
In some cases, the <b>excl::atomically</b> form was used not to assure
atomicity, or to guarantee gc-free running, but to wrap a section of
code that needed to be as fast as possible. If some infelicitous
change to the compiler caused it to start generating out-of-line calls
where in-line code was expected, the presence of
the <b>excl::atomically</b> wrapper made sure there would be a
compile-time warning.
</p>
<p id="55">
The new macro <a href="operators/excl/fast-and-clean.htm"><b>fast-and-clean</b></a>
replaces <b>excl::atomically</b>. In an SMP
Lisp, <code>(fast-and-clean ...)</code>, which is the functional
equivalent of <code>(excl::atomically ...)</code>, cannot be
guaranteed to be atomic because of the nature of SMP and atomicity. It
will, however, prevent a gc from happening while the form is
executing, because gc's can only happen when a process allocates
something or at one of the same "safe-point"s that allow interrupts
(described below
in <a href="#without-interrupts-2">Section 2.2 Deprecated macro: without-interrupts</a>). The
<a href="operators/excl/fast-and-clean.htm"><b>fast-and-clean</b></a> form assures
us we have neither of these. Even so, if control of garbage collection
is the issue, using the <a href="operators/excl/with-pinned-objects.htm"><b>with-pinned-objects</b></a> macro is preferred.
</p>



<hr><h2 id="56"><a name="without-interrupts-2">2.2 Deprecated macro: without-interrupts</a></h2>

<p id="57">
The <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> macro
works as follows:
</p>

<pre id="58">
(without-interrupts . BODY)
</pre>

<p id="59">
acts almost exactly like
</p>

<pre id="60">
(let ((excl::*without-interrupts* t)) BODY)
</pre>

<p id="61">
<b><code>excl::*without-interrupts*</code></b> is a special
variable (named by an unexported symbol and so not documented) which
gates the processing of asynchronous signals. When an asynchronous
signal triggers Lisp's low-level signal handler, the signal is queued
and a flag is set to indicate the situation. This happens without any
Lisp code executing, and does not interrupt the running Lisp
code. While executing, Lisp code polls the flag periodically, checking
for the signal-has-happened situation.
</p>
<p id="62">
These checks are made at safe-points in the code, where the Lisp
system is ready to allow execution of arbitrary signal-handling code
in an interrupt-the-application mode; handling the signals at the Lisp
level could result in a process-interrupt, or cause a process switch
in a non-SMP Lisp.
If <b><code>excl::*without-interrupts*</code></b>
is <code>nil</code>, then the safe-point check happens
normally, and any queued signals get
handled. If <b><code>excl::*without-interrupts*</code></b> is
non-<code>nil</code>, then queued signals are ignored. No
process-interrupt will be handled, and in a non-SMP Lisp, no automatic
process switch can happen
when <b><code>excl::*without-interrupts*</code></b> is
non-<code>nil</code>, although an explicit process-wait or
other scheduling operation would break through this barrier.
</p>
<p id="63">
Ignored signals are not discarded, and signals caught while
<b><code>excl::*without-interrupts*</code></b> is
non-<code>nil</code> will still be added to the queue of
pending signals, to be processed at some safe-point after leaving the
without-interrupts regime. The way in which without-interrupts differs
from the simple <b>let</b> form shown above has to do with details of
safe and efficient processing, ensuring that we pay as little as
possible in computation overhead to ignore the pending signals and
that when <b><code>excl::*without-interrupts*</code></b> returns
to a <code>nil</code> value, we handle any pending signals
at the next safe-point.
</p>
<p id="64">
However, even though interrupts are delayed and process switches from
the code running within a <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> are also inhibited, object
locking, a side effect in a non-SMP Lisp is no longer guaranteed and
gc's may occur even if the code within the <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> form does no consing and so
does not itself trigger a gc.
</p>
<p id="65">
The new macro <a href="operators/excl/with-delayed-interrupts.htm"><b>with-delayed-interrupts</b></a> replaces
<a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>. In a
non-SMP Lisp, <a href="operators/excl/with-delayed-interrupts.htm"><b>with-delayed-interrupts</b></a> expands to the same
code as <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>
(but does not produce a compiler warning). In an SMP Lisp, interrupts
are delayed, so the code within the macro runs to completion once it
is started, but objects are not locked as other processes can run.
</p>



<hr><h2 id="66"><a name="without-scheduling-2">2.3 Deprecated macro: sys:without-scheduling</a></h2>

<p id="67">
<a href="operators/system/without-scheduling.htm"><b>sys:without-scheduling</b></a>
worked as follows:
</p>

<pre id="68">
(without-scheduling . BODY)
</pre>

<p id="69">
worked like
</p>

<pre id="70">
(let ((*disallow-scheduling* t))
  (progn . BODY))
</pre>

<p id="71">
<a href="variables/system/s_disallow-scheduling_s.htm"><code>*disallow-scheduling*</code></a> is a special variable
that gates automatic process switches in non-SMP Lisps. It is checked
when other factors indicate it is time to stop the currently running
process and let another one have control for a while. If it
is <code>nil</code>, then the switch will happen; if
non-<code>nil</code>, the switch will be prohibited and
the current process will continue running. <a href="variables/system/s_disallow-scheduling_s.htm"><code>sys:*disallow-scheduling*</code></a> finds some
specialized uses, as when it is important to honor <a href="operators/system/with-timeout.htm"><b>sys:with-timeout</b></a> requests (which require
handling timer signals, which would be ignored by <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>) without allowing a process
switch to occur.
</p>
<p id="72">
There is no exact replacement for sys:without-scheduling since the
model for processes is changed and the concept of process switching is
nearly without meaning. If you use sys:without-scheduling, the
question is why? If the purpose was object locking (ensuring that
values are not read or written by other processes while code runs),
you have to use the new object locking routines. If the purpose was to
ensure that the process ran to completion but also allowed for signal
processing (for <a href="operators/system/with-timeout.htm"><b>sys:with-timeout</b></a>, for example), that is no
longer supported.
</p>



<hr><hr><h2 id="73"><a name="new-macs-1">3.0 New macros and related functionality</a></h2>

<p id="74">
We provide new macros for efficient object-level synchronization.
Some of these involve locking objects, and others are atomic
read-modify-write primitives. We also provide a set of macros to perform
those functions of the deprecated macros that did not serve to synchronize
access to specific objects. 
</p>
<p id="75">
A Lisp that actually supports SMP has <code>:smp</code> on its
<a href="../ansicl/dictentr/features.htm"><code>*features*</code></a> list. A Lisp
that supports these new macros has <code>:smp-macros</code> on
its <a href="../ansicl/dictentr/features.htm"><code>*features*</code></a>
list. Thus a 9.0 smp-enabled Lisp has both <code>:smp</code> and
<code>:smp-macros</code> on its <a href="../ansicl/dictentr/features.htm"><code>*features*</code></a> list, while an 8.2 Lisp, a patched
8.1 Lisp, or a non-SMP 9.0 Lisp have the
feature <code>:smp-macros</code> but
not <code>:smp</code>. See <a href="implementation.htm#reader-macros-2">Reader macros and cl:*features*</a>
in <a href="implementation.htm">implementation.htm</a> for more information on
features.
</p>
<p id="76">
All the symbols naming the functions, macros, classes and structure types
added as part of SMP are exported from the excl package.
</p>

<hr><h2 id="77"><a name="non-sync-2">3.1 Non-synchronizing usages</a></h2>

<p id="78">
The first three new macros provide the non-concurrent-access-related
uses of the old <b>excl::atomically</b> and <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> macros.
</p>
<ul>
<li id="79">
<a href="operators/excl/fast-and-clean.htm"><b>fast-and-clean</b></a>: replaces
<b>excl::atomically</b>. It provides compile-time information about the
code it wraps.
</li>
<li id="80">
<a href="operators/excl/with-pinned-objects.htm"><b>with-pinned-objects</b></a>: this
replaces another use of <b>excl::atomically</b>, which was to ensure
that objects did not move because of a gc. <b>excl::atomically</b>
could ensure a gc did not happen. Gc's only happen when all processes
permit it, and the process running <a href="operators/excl/with-pinned-objects.htm"><b>with-pinned-objects</b></a> will not permit a gc and
will not fail because it does not allocate.
</li>
<li id="81">
<a href="operators/excl/with-delayed-interrupts.htm"><b>with-delayed-interrupts</b></a>:
this replaces <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>. It evaluates and compiles
exactly as <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a> did. In an SMP Lisp it
provides no cross-process protection of shared objects. Its entire
purpose in that environment is to protect blocks of code that need to
run to completion even in the face of timeouts and possible
process-interrupt calls from other processes.
</li>
</ul>



<hr><h2 id="82"><a name="read-write-2">3.2 Atomic read-modify-write primitives</a></h2>

<p id="83">
When an atomic operation fits the pattern
</p>

<pre id="84">
(setf [place] (foo [place]))
</pre>

<p id="85">
and [place] is one of several inline-accessible 'slots' like (car x),
the compiler can generate code to ensure that the value in [place]
doesn't change between the initial read and the subsequent write.
There are several macros that provide special cases of this operation,
and a general conditional-update form on which all of them are based.
[place] can be any of the following <a href="../ansicl/dictentr/setfpset.htm"><b>setf</b></a>-places:
</p>
<ul>
<li id="86">
(global-symbol-value symbol-form)
</li>
<li id="87">
symbol
</li>
<li id="88">
(car cons-form)
</li>
<li id="89">
(cdr cons-form)
</li>
<li id="90">
(memref object-form offset-form pos-form size-form)
</li>
<li id="91">
(memref-int address-form offset-form pos-form size-form)
</li>
<li id="92">
(svref array-form index-form)
</li>
<li id="93">
(structure-slot-ref structure-form)
</li>

<li id="94">
(slot-value x y) (This works as long as the slot is a normal instance
or class slot with no added slot-value methods. It does not work
for <b>slot-value-using-class</b>.)
</li>
<li id="95">
(symbol-plist x)
</li>
<li id="96">
Local or special bound variables. (Note that atomic setting of these
is unusual because local places are not shared between
multiple processes.)
</li>

</ul>
<p id="97">
These places are a subset of places legal for <a href="../ansicl/dictentr/setfpset.htm"><b>setf</b></a>. 
</p>
<p id="98">
The relevant macros are:
</p>
<ul>
<li id="99">
<a href="operators/excl/incf-atomic.htm"><b>incf-atomic</b></a>
and <a href="operators/excl/decf-atomic.htm"><b>decf-atomic</b></a>: these
expand into code that acts like <a href="../ansicl/dictentr/incfdecf.htm"><b>incf</b></a> or <a href="../ansicl/dictentr/incfdecf.htm"><b>decf</b></a> with the same arguments except that the
update is atomic with respect to any other processes looking at the
same [place]. That is, if several processes simultaneously try to
<a href="operators/excl/incf-atomic.htm"><b>incf-atomic</b></a> and/or
<a href="operators/excl/decf-atomic.htm"><b>decf-atomic</b></a> the same
location, all operations occur sequentially in some unspecified order.
</li>
<li id="100">
<a href="operators/excl/push-atomic.htm"><b>push-atomic</b></a>
and <a href="operators/excl/pop-atomic.htm"><b>pop-atomic</b></a>: these expand
into code that acts like <a href="../ansicl/dictentr/push.htm"><b>push</b></a>
or <a href="../ansicl/dictentr/pop.htm"><b>pop</b></a> with the same
arguments except that the update to [place] is atomic with respect to
all other processes looking at the same [place]. That is, any number
of simultaneous <a href="operators/excl/push-atomic.htm"><b>push-atomic</b></a>
and <a href="operators/excl/pop-atomic.htm"><b>pop-atomic</b></a> operations on
the same location will act as if they occurred sequentially in some
unspecified order.
</li>
<li id="101">
<a href="operators/excl/atomic-conditional-setf.htm"><b>atomic-conditional-setf</b></a>:
this is the primitive form on which the previous atomic operations are
based. It acts very much like <code>(when (eq [place] oldval-form)
(setf [place] newval-form) t)</code> except that the subforms of
[place] are evaluated just once, the comparison and store, if there is one,
are an atomic sequence.
</li>

<li id="102">
<a href="operators/excl/atomic-conditional-setq.htm"><b>atomic-conditional-setq</b></a>:
this special operator returns a boolean of success or failure to store
the value into the symbol's value location.  It is intended to be a
synchronizing mechanism for symbols which represent variables shared
by multiple threads.
</li>

<li id="103">
<a href="operators/excl/update-atomic.htm"><b>update-atomic</b></a>: this macro
expands into code that does a read-modify-write operation that is
atomic with respect to the value in a place.
</li>
<li id="104">
<a href="operators/excl/globalq.htm"><b>globalq</b></a>: <code>(globalq
x)</code> is a macro shorthand
for <code>(system:global-symbol-value 'x)</code>.
</li>
<li id="105">
<a href="operators/excl/defvar-nonbindable.htm"><b>defvar-nonbindable</b></a>: this
acts like a <a href="../ansicl/dictentr/defparam.htm"><b>defvar</b></a>, with the
additional function of flagging symbol so that it cannot be
lambda-bound. 
</li>
<li id="106">
<a href="operators/excl/get-atomic-modify-expansion.htm"><b>get-atomic-modify-expansion</b></a>:
this function is called by the atomic-modify macro expanders to find
out how to treat place-form. It returns six values.
</li>
</ul>




<hr><h2 id="107"><a name="concur-2">3.3 Concurrency control for shared objects</a></h2>

<p id="108">
None of the deprecated macros provide effective concurrency control in
an smp lisp. New macros are provided to give the programmer tools for
controlling concurrent access. There is no way to make the change to
smp automatic and painless. The crux of the problem is that in the
absence of smp, one-sided concurrency control works. That is, a
process modifying a shared object could wrap a series of modifications
with pre-8.2 forms like those using <a href="operators/excl/without-interrupts.htm"><b>without-interrupts</b></a>, and be assured that all
processes would see those changes as an atomic transaction. The forms
themselves assured that no other process would see the object until
all the changes were in place.
</p>
<p id="109">
A confounding factor is that pre-8.2 concurrency was very
coarse-grained. Processes were preempted at a very low frequency,
typically once in 2 seconds, unless they explicitly waited on some
condition. Even with no attempt at concurrency control, it was rare to
see an inconveniently-timed process switch break a transaction that
should have been atomic.
</p>
<p id="110">
In an SMP Lisp, concurrency is as fine-grained as it could possibly be.
Writers and readers must all cooperate to ensure that access to shared
structures is legitimate.
</p>
<p id="111">
Allegro CL has a set of object-locking macros. These are lighter weight
and less flexible than the <a href="operators/mp/process-lock.htm"><b>mp:process-lock</b></a> features, and do not rely on
the mp package. They must be used with care to avoid deadlocks.
</p>
<p id="112">
The macros and related functionality are:
</p>

<ul>
<li id="113">
<a href="operators/excl/with-locked-structure.htm"><b>with-locked-structure</b></a>:
expands into code that waits until the executing process acquires
control of its argument structure object, then evaluates the forms in
the body as an implicit <a href="../ansicl/dictentr/progn.htm"><b>progn</b></a>. It then releases control of the object
and returns whatever values the last form in the body returned.
</li>
<li id="114">
<a href="classes/excl/synchronizing-structure.htm"><code>synchronizing-structure</code></a>:
this structure class is used as a base structure when instances of a
structure class are to be locked with the <a href="operators/excl/with-locked-structure.htm"><b>with-locked-structure</b></a> macro.
</li>
<li id="115">
<a href="classes/excl/basic-lock.htm"><code>basic-lock</code></a>: this
structure class is a simple extension of synchronizing-structure,
adding a name slot.
</li>
<li id="116">
<a href="operators/excl/with-locked-object.htm"><b>with-locked-object</b></a>: this
macro expands into code that waits until the executing process
acquires control of the object, then evaluates the forms in the body
as an implicit progn. It then releases control of the object and
returns whatever values the last form in the body returned.
</li>
<li id="117">
<a href="operators/excl/with-object-lock-released.htm"><b>with-object-lock-released</b></a>:
this macro can only appear lexically inside the body of
a <a href="operators/excl/with-locked-object.htm"><b>with-locked-object</b></a>
macro. The lock obtained in the immediately enclosing
<a href="operators/excl/with-locked-object.htm"><b>with-locked-object</b></a> macro is
released, body is executed, and then the lock is re-obtained.
</li>
<li id="118">
<a href="classes/excl/lockable-object.htm"><code>lockable-object</code></a>: this is
a mixin class that allows subclasses to be used in the
<a href="operators/excl/with-locked-object.htm"><b>with-locked-object</b></a>
macro.
</li>
<li id="119">
<a href="operators/excl/with-locked-stream.htm"><b>with-locked-stream</b></a>: like
<a href="operators/excl/with-locked-object.htm"><b>with-locked-object</b></a>, but
applies to objects that are streams.
</li>
<li id="120">
<a href="operators/excl/critical-section.htm"><b>critical-section</b></a>: this macro
expands into code that uses a unique basic-lock associated with the
expansion to control execution of the body code. Only one process at a
time can acquire ownership of the lock and execute the forms in body.
Ownership of the lock is relinquished when control leaves body by
falling through or by non-local exit. The result of evaluating
the <a href="operators/excl/critical-section.htm"><b>critical-section</b></a> code is
the result of the last form in body.
</li>
</ul>



<hr><h2 id="121"><a name="sharable-locks-2">3.4 Sharable locks</a></h2>



<p id="122">
A sharable lock allows multiple user threads to access a resource
simultaneously when it is safe and appropriate to share it.  When
exclusive use of the resource is required, a thread can ask for
exclusive access.  During exclusive access, all shared access is
blocked.  A typical use case is a data structure that can be safely
accessed in read-only mode by many threads but requires exclusive
access while the data structure is modified and may be temporarily in
an inconsistent state.
</p>
<p id="123">
A <a href="classes/mp/sharable-lock.htm"><code>sharable-lock</code></a> instance is
created with <a href="operators/mp/make-sharable-lock.htm"><b>make-sharable-lock</b></a>.  Locking contexts are
provided with the macros <a href="operators/mp/with-sharable-lock.htm"><b>with-sharable-lock</b></a>.
An application can
manage locking explicitly with <a href="operators/mp/sharable-lock-lock.htm"><b>sharable-lock-lock</b></a> and <a href="operators/mp/sharable-lock-unlock.htm"><b>sharable-lock-unlock</b></a>.
</p>
<p id="124">
An important parameter in the definition of Allegro CL sharable locks
is the max-shared count that specifies the maximum number of
simultaneous shared users of a lock.  When the maximum number of
simultaneous shared users is reached additional attempts to share the
lock must wait until some shared threads release control.
</p>
<p id="125">
Once a thread requests exclusive access, subsequent request for shared
access must wait until the exclusive request is honored and completed.
Because there is a limit on the number of shared users, there is an
upper bound on the delay that the exclusive request can endure.
While an exclusive locker is running, shared requests are accepted
until the max-shared limit is reached.  These shared requests will be
honored as soon as the exclusive user releases the lock. If another
exclusive request arrives before the first is done, it will wait until
the first exclusive request and up to max-shared shared requests are
honored.  
</p>
<p id="126">
If several threads compete for exclusive access, it is possible to
create a situation where an exclusive request is delayed indefinitely.
The only solution in this case is to reduce the frequency of exclusive
requests or to speed up their handling.  It is also possible to delay
shared requests indefinitely if too many threads compete for shared
access.  Such a situation can be alleviated by increasing the
max-shared value.  The size of a sharable lock is proportional to the
max-shared value, but values in the thousands are still reasonable.
</p>
<p id="127">
In the current implementation of sharable-lock, the fairness policy is
strong writer preference.  When an exclusive lock is requested, only
the current shared users are allowed to continue.  New requests for a
shared (reader) lock must wait until the exclusive (writer) request is
honored and completed.  While an exclusive lock is in effect, shared
requests up to the max-shared limit are allowed but remain pending
until the exclusive lock is released.
</p>

<h3 id="128">
Sharable-lock functionality
</h3>

<ul>
<li id="129">
<a href="classes/mp/sharable-lock.htm"><code>sharable-lock</code></a>: the class of a sharable-lock object.
</li>
<li id="130">
<a href="operators/mp/exclusive-locker-count.htm"><b>exclusive-locker-count</b></a>,
Generic Function
</li>
<li id="131">
<a href="operators/mp/make-sharable-lock.htm"><b>make-sharable-lock</b></a>, Function
</li>
<li id="132">
<a href="operators/mp/sharable-lock-lock.htm"><b>sharable-lock-lock</b></a>, Generic Function
</li>
<li id="133">
<a href="operators/mp/sharable-lock-unlock.htm"><b>sharable-lock-unlock</b></a>, Generic Function
</li>
<li id="134">
<a href="operators/mp/shared-locker-count.htm"><b>shared-locker-count</b></a>,
Generic Function
</li>
<li id="135">
<a href="operators/mp/with-sharable-lock.htm"><b>with-sharable-lock</b></a>, Macro
</li>
<li id="136">
<a href="operators/mp/with-exclusive-lock.htm"><b>with-exclusive-lock</b></a>, Macro
(<b>Use of this macro is deprecated</b>)
</li>
<li id="137">
<a href="operators/mp/with-shared-lock.htm"><b>with-shared-lock</b></a>, Macro
(<b>Use of this macro is deprecated</b>)
</li>
</ul>

<h3 id="138">
Errors signaled from sharable-lock operators:
</h3>

<ul>
<li id="139">
<a href="classes/mp/sharable-lock-error.htm"><code>sharable-lock-error</code></a>
</li>
<li id="140">
<a href="classes/mp/sharable-lock-recursion-error.htm"><code>sharable-lock-recursion-error</code></a>
</li>
<li id="141">
<a href="classes/mp/sharable-lock-unlock-error.htm"><code>sharable-lock-unlock-error</code></a>
</li>
<li id="142">
<a href="classes/mp/sharable-lock-interrupted-error.htm"><code>sharable-lock-interrupted-error</code></a>
</li>
</ul>



<hr><h2 id="143"><a name="barrier-api-2">3.5 The barrier API</a></h2>



<p id="144">
A barrier instance allows several threads to share progress
information or to synchronize their behavior.  A newly created barrier
is initialized in the enabled state with an expected count and an
arriver count of zero.  As each thread arrives at or passes through
the barrier, the arriver count is incremented.  All <a href="operators/mp/barrier-wait.htm"><b>barrier-wait</b></a> calls will block until the arriver
count reaches the specified expcted count.
</p>
<p id="145">
The state of a barrier can set to disabled. A disabled barrier is
simply ignored -- passing through a disabled barrier has no effect,
and call to <a href="operators/mp/barrier-wait.htm"><b>barrier-wait</b></a>
returns immediately.
</p>
<p id="146">
A typical application of barriers is to synchronize several threads to
start some computation simultaneously.  The program creates a barrier
with a count of N; each of the N threads calls <a href="operators/mp/barrier-wait.htm"><b>barrier-wait</b></a> and blocks.  When the slowest
thread reaches the barrier, all the threads are released.
</p>
<p id="147">
Another application of barriers is to allow one thread to detect when
several threads have completed some task.  The control thread creates
a barrier with a count of (N+1) and calls <a href="operators/mp/barrier-wait.htm"><b>barrier-wait</b></a>; each of the N worker threads calls
<a href="operators/mp/barrier-pass-through.htm"><b>barrier-pass-through</b></a> when it
completes the task.  When the Nth thread calls <a href="operators/mp/barrier-pass-through.htm"><b>barrier-pass-through</b></a>, the <a href="operators/mp/barrier-wait.htm"><b>barrier-wait</b></a> in the control thread returns.
</p>

<h3 id="148">
Barrier API functionality
</h3>

<ul>
<li id="149">
<a href="classes/mp/barrier.htm"><code>barrier</code></a>, class
</li>
<li id="150">
<a href="operators/mp/barrier-name.htm"><b>barrier-name</b></a>, generic-function
</li>
<li id="151">
<a href="operators/mp/barrier-arriver-count.htm"><b>barrier-arriver-count</b></a>, generic-function
</li>
<li id="152">
<a href="operators/mp/barrier-change-count.htm"><b>barrier-change-count</b></a>, generic-function
</li>
<li id="153">
<a href="operators/mp/barrier-enable.htm"><b>barrier-enable</b></a>, generic-function
</li>
<li id="154">
<a href="operators/mp/barrier-disable.htm"><b>barrier-disable</b></a>, generic-function
</li>
<li id="155">
<a href="operators/mp/barrier-pass-through.htm"><b>barrier-pass-through</b></a>, generic-function
</li>
<li id="156">
<a href="operators/mp/barrier-unblock.htm"><b>barrier-unblock</b></a>, generic function
</li>
<li id="157">
<a href="operators/mp/barrier-wait.htm"><b>barrier-wait</b></a>, generic-function
</li>
<li id="158">
<a href="operators/mp/make-barrier.htm"><b>make-barrier</b></a>, function
</li>
</ul>



<hr><h2 id="159"><a name="queue-2">3.6 Queues</a></h2>

<p id="160">
The <a href="classes/mp/queue.htm"><code>mp:queue</code></a> class and the
functions for using it are very safe, but relatively
heavy-weight. Becasue they use <a href="operators/mp/process-lock.htm"><b>mp:process-lock</b></a> to control access to
the queue, they use more resources than something based on
<a href="operators/excl/with-locked-object.htm"><b>with-locked-object</b></a>.
</p>
<p id="161">
A reasonable development approach would be to use an instance of
mp:queue for transmitting information from producers to consumers,
with the option of later coding a lighter-weight application-specific
mechanism if performance tests showed the queue to be a significant
cost factor. 
</p>




<hr><h2 id="162"><a name="condition-vars-2">3.7 Condition Variables</a></h2>

<p id="163">
Condition variables are another way to synchronize the behavior of multiple
threads. They are normally used in conjunction with a lock that controls
the modification of some data structure.  
</p>
<p id="164">
The Allegro CL implementation of condition-variable is based on the
definition of POSIX condition variables. The relevant functionality is
implemented with the following class and functions.
</p>

<ul>
<li id="165">
<a href="classes/mp/condition-variable.htm"><code>condition-variable</code></a>: class.
</li>
<li id="166">
<a href="operators/mp/make-condition-variable.htm"><b>make-condition-variable</b></a>: function.
</li>
<li id="167">
<a href="operators/mp/condition-variable-wait.htm"><b>condition-variable-wait</b></a>:
function.
</li>
<li id="168">
<a href="operators/mp/condition-variable-wait-count.htm"><b>condition-variable-wait-count</b></a>:
function.
</li>
<li id="169">
<a href="operators/mp/condition-variable-signal.htm"><b>condition-variable-signal</b></a>:
function.
</li>
<li id="170">
<a href="operators/mp/condition-variable-broadcast.htm"><b>condition-variable-broadcast</b></a>:
function.
</li>
</ul>




<hr><hr><h2 id="171"><a name="safe-ops-1">4.0 Safe and unsafe operators</a></h2>

<p id="172">
An operator which accesses or sets the value stored in an object is
<b>safe</b> when it can be called in a number of processes, otherwise
unsynchronized by user code, and the result is the same as if the
operations were done sequentially in a single process though in an
unspecified order. Therefore, safe operations will not error and will
not produce bogus results (results that could never have occurred no
matter in what order the operations were done). But safe operations
will not necessarily produce the same results in repeated runs.
</p>
<p id="173">
Unsafe operators are those which could unexpectedly error or could
produce results which are bogus according to the definition above.
</p>
<p id="174">
For operators that do not make any changes (i.e. do not set values), safety
means that the result will be meaningful and correct for some
instantaneous state of the data structure. Each thread will see a data
structure in a consistent state. Operators that modify data are
safe if they see data structures in some instantaneous consistent
state, and leave the data structure in a consistent state.
</p>
<p id="175">
It is important to emphasize, so we will say it again, that safe
operators are not guaranteed to produce the same result in repeated
runs, just a result that is consistent with some possible sequence of
evaluation, produced by some interleaving of the operations from the
multiple processes.
</p>
<h3 id="176">
Safe operators and operations
</h3>
<ul>
<li id="177">
<a href="../ansicl/dictentr/gethash.htm"><b>gethash</b></a> and <a href="../ansicl/dictentr/gethash.htm"><b>(setf gethash)</b></a>: these are safe
operations. You will always get a result that could have arisen from
the operations done in some possible sequence in a single process. (A
possible sequence is one that interleaves the sequences from each
individual process, preserving the order of calls in each specific
process.)
</li>
<li id="178">
<a href="../ansicl/dictentr/remhash.htm"><b>remhash</b></a> is thread safe but is
not guaranteed to be atomic.
</li>
<li id="179">
Property list functions <a href="../ansicl/dictentr/get.htm"><b>get</b></a>,
<a href="../ansicl/dictentr/get.htm"><b>(setf
get)</b></a>, <a href="../ansicl/dictentr/getf.htm"><b>getf</b></a>, <a href="../ansicl/dictentr/getf.htm"><b>(setf getf)</b></a>, <a href="../ansicl/dictentr/remf.htm"><b>remf</b></a>, <a href="../ansicl/dictentr/remprop.htm"><b>remprop</b></a>: these are safe so long as all processes
modifying the property list use these operators. If a process modifies
the property list using other operator (such a <a href="../ansicl/dictentr/carcdrca.htm"><b>(setf car)</b></a> or <a href="../ansicl/dictentr/nth.htm"><b>(setf nth)</b></a>), then the listed
functions are not safe.
</li>
</ul>

<h3 id="180">
Unsafe operators
</h3>
<p id="181">
Basically any operator that modifies a value is unsafe except those
listed above and the atomic operators described elsewhere in this
document. In particular sequence functions and their <a href="../ansicl/dictentr/setfpset.htm"><b>setf</b></a>'s are unsafe. Operators
like <a href="../ansicl/dictentr/pushnew.htm"><b>pushnew</b></a>, which is
supposed to guarantee that duplicates are not added is unsafe and may
produce results that have unexpected duplicates.
</p>

<h3 id="182">
Safe modules
</h3>

<p id="183">
The jLinker (see <a href="jlinker.htm">jlinker.htm</a>) and the dbi (or
aodbc) modules (see <a href="aodbc.htm">aodbc.htm</a>) are thread safe in
SMP or non-SMP Lisps.
</p>

<hr><h2 id="184"><a name="general-lisp-unsafe-2">4.1 Unsafe standard Lisp operations: *features*, *modules*, require/provide, external-format loading, etc.</a></h2>

<p id="185">
Certain standard Common Lisp operations and some standard Allegro CL
operations cannot be conveniently be made thread safe. Here we
summarize many of these issues.
</p>
<ul>
<li id="186">
<b>Modification of global variables</b>. This must be handled by each
application in its own way.  There cannot be an automatic built-in
procedure.  For example, <a href="../ansicl/dictentr/pushnew.htm"><b>pushnew</b></a> to <a href="../ansicl/dictentr/features.htm"><code>*features*</code></a> or <a href="../ansicl/dictentr/modules.htm"><code>*modules*</code></a> is not thread-safe.
</li>
<li id="187">
<b>defvar is not atomic and therefore not thread-safe</b>.  Since
<a href="../ansicl/dictentr/defparam.htm"><b>defvar</b></a> occurs mostly
in files, thread-safety is managed with the same strategy as
require/provide below.
</li>
<li id="188">
<b>sys:*all-processes*</b>: the variable <a href="variables/system/s_all-processes_s.htm"><code>sys:*all-processes*</code></a> must be treated with the
caution described on the documentation page.
</li>
<li id="189">
<b>The activities of require/provide/load cannot be made
thread-safe</b>.  Applications must use their own protocols or locks
to make sure files are loaded sequentially.  Autoloading is safe
because in Allegro CL there are internal locks and constraints on the
content of autoloaded files.  Unfortunately, the locks and
constraints cannot be safely exported or generalized.
</li>
<li id="190">
<b>External format loading is not thread-safe</b>. Applications must
arrange for the sequential loading of external formats. 
</li>
<li id="191">
All definition operators (<a href="../ansicl/dictentr/defun.htm"><b>defun</b></a>, <a href="../ansicl/dictentr/defmacro.htm"><b>defmacro</b></a>, etc.) are non-atomic and
unsafe.
</li>
<li id="192">
ALL MOP operations that modify class structure or method dispatch are
non-atomic and unsafe.
</li>
<li id="193">
Some <a href="../ansicl/dictentr/make-ins.htm"><b>make-instance</b></a>
calls are unsafe. See the note just below.
</li>
</ul>

<h3 id="194">
Note on safety of make-instance
</h3>
<p id="195">
Consider a compiled call to <a href="../ansicl/dictentr/make-ins.htm"><b>make-instance</b></a> where the class and all
the keywords are constants. If such a call is compiled or loaded into
a Lisp image where the class is not yet defined, then the first
execution of this call is not thread-safe. The workaround is to avoid
such calls. The following fwrapper can be used to warn if such code
is loaded (see <a href="fwrappers-and-advice.htm">fwrappers-and-advice.htm</a> for information
on the fwrap facility):
</p>

<pre id="196">
   (def-fwrapper warn-cons (class-or-name inits)
     (when (and (symbolp class-or-name)
     	        (null (find-class class-or-name nil)))
       (warn "Delayed constructor call for ~S" class-or-name))
       (call-next-fwrapper))

   (fwrap 'excl::ensure-constructor :warn-cons 'warn-cons)
</pre>



<hr><h2 id="197"><a name="smp-mop-2">4.2 SMP and the MOP</a></h2>

<p id="198">
The MetaObject Protocol (MOP) implementation in Allegro CL makes no
effort to support multithreaded use of objects and generic functions
while a class definition is being changed. Dispatch functions work
with multi-threaded accesses that might update their caches, but
keeping things straight when a class is being redefined is not
manageable.
</p>
<p id="199">
An application that updates a class definition while it is running
should be designed to ensure that none of the objects are accessed,
even for generic-function dispatch, until the redefinition is complete.
</p>




<hr><h2 id="200"><a name="suspend-all-2">4.3 Suspending all processes</a></h2>

<p id="201">
It is not possible to suspend all threads programmatically.  (All
processes are suspended in a garbage collection but this cannot
generalized.)
</p>



<hr><hr><h2 id="202"><a name="non-smp-1">5.0 Ensuring code is not loaded into an SMP Lisp</a></h2>

<p id="203">
Some code you may have may not be SMP safe. However, this code will
typically load and run in an SMP Lisp (probably producing incorrect
results, perhaps silently). If you have a source file which should not
be run in an SMP lisp, add this form to the top:
</p>

<pre id="204">
   (eval-when (compile load eval)
     (when (featurep :smp)
       (error "This cannot run in an SMP lisp")))
</pre>


<hr><hr><h2 id="205"><a name="memlog-1">6.0 Memlog: A Facility for Minimally Intrusive Monitoring             of Complex Application Behavior</a></h2>

<p id="206">
The Lisp <a href="debugging.htm#tracer-1">trace</a>
facility is a powerful and effective tool for monitoring and analyzing
the behavior of a complex application. But when the application uses
many threads, the trace output suffers from several drawbacks:
</p>
<ul>
<li id="207">
The generation of output to a stream introduces significant timing
disruptions in the application.
</li>
<li id="208">
Unsynchronized trace output can be garbled and unreadable.
</li>
<li id="209">
If trace output is synchronized, the timing disruption is even more severe.
</li>
</ul>
<p id="210">
The <b>memlog</b> module implements a facility for making log entries
into a memory data structure. By avoiding i/o operations a memory
logging facility can have much less impact on the timing of the
monitored application.
</p>
<p id="211">
The run-time operations in the memlog module are carefully designed
and implemented to be thread-safe and effective in both SMP and non-SMP 
environments.
</p>
<p id="212">
The trace definition operations, <a href="operators/mp/memtrace.htm"><b>memtrace</b></a> and <a href="operators/mp/memuntrace.htm"><b>memuntrace</b></a>, like many other operations that
alter the state of the running Lisp system (MOP, <a href="operators/excl/fwrap.htm"><b>fwrap</b></a>, <a href="../ansicl/dictentr/provider.htm"><b>require</b></a>, <a href="../ansicl/dictentr/provider.htm"><b>provide</b></a>, ...), cannot be made thread-safe at any
reasonable cost.
</p>
<p id="213">
The operators associated with this facility are the
following. Evaluate <code>(require :smputil)</code> to ensure
the definitions are loaded into Lisp. All symbols naming these
operators are in the <code>multiprocessing</code> package.
</p>
<ul>
<li id="214">
<a href="operators/mp/memlog.htm"><b>memlog</b></a> (Function)
</li>
<li id="215">
<a href="operators/mp/memtrace.htm"><b>memtrace</b></a> (Macro)
</li>

<li id="216">
<a href="operators/mp/memtrace-def.htm"><b>memtrace-def</b></a> (Macro)
</li>

<li id="217">
<a href="operators/mp/memuntrace.htm"><b>memuntrace</b></a> (Macro)
</li>
<li id="218">
<a href="operators/mp/memlog-init.htm"><b>memlog-init</b></a> (Function)
</li>
<li id="219">
<a href="operators/mp/memlog-start.htm"><b>memlog-start</b></a> (Function)
</li>
<li id="220">
<a href="operators/mp/memlog-stop.htm"><b>memlog-stop</b></a> (Function)
</li>
<li id="221">
<a href="operators/mp/memlog-copy.htm"><b>memlog-copy</b></a> (Function)
</li>
<li id="222">
<a href="operators/mp/memlog-show.htm"><b>memlog-show</b></a> (Function)
</li>
<li id="223">
<a href="operators/mp/memlog-disable.htm"><b>memlog-disable</b></a> (Function)
</li>
<li id="224">
<a href="operators/mp/memlog-state.htm"><b>memlog-state</b></a> (Function)
</li>
<li id="225">
<a href="operators/mp/memlog-entry.htm"><b>memlog-entry</b></a> (Function)
</li>
</ul>

<h3 id="226">
Example
</h3>
<pre id="227">
;; We define FACT which calculates the factorial of its (positive integer)
;; argument. We first use traditional tracing. We are in the IDE, and tracing
;; output (by default) goes to the listener for operators called in the Listener
;; and to the console for operatiors called in other thread. 
;; Then we stop tracing and initiate memlogging. Now output goes to a memlog object
;; and we can choose to see all output or just that relating to a particular
;; thread.
;;
cg-user(4): (defun fact (n) (if (zerop n) 1 (* n (fact (1- n)))))
fact
cg-user(5): (trace fact)
(fact)
cg-user(6): (fact 3)
 0[4]: (fact 3)
   1[4]: (fact 2)
     2[4]: (fact 1)
       3[4]: (fact 0)
       3[4]: returned 1
     2[4]: returned 1
   1[4]: returned 2
 0[4]: returned 6
6
cg-user(8): (mp:process-run-function &quot;ftest&quot; #'fact 3)
#&lt;multiprocessing:process ftest(5) @ #x2028bbd82&gt;

;; In the IDE, trace output (by default) goes to the console when operators
;; are not run in the Listener thread (behavior when not running the IDE is
;; different). Looking at the console, we see:
;;
;; cl-user(1): 
;; 0[5]: (common-graphics-user::fact 3)
;;   1[5]: (common-graphics-user::fact 2)
;;     2[5]: (common-graphics-user::fact 1)
;;       3[5]: (common-graphics-user::fact 0)
;;       3[5]: returned 1
;;     2[5]: returned 1
;;   1[5]: returned 2
;; 0[5]: returned 6
;;
;; We stop all tracing:

cg-user(10): (untrace)
nil

;; And we start MEMLOGGING:
;; First we load the module:
;;
cg-user(11): (require :smputil)
; Fast loading C:\acl100b2.64\code\smputil.fasl
t

;; We create a mlog object:

cg-user(12): (setq mlog (mp:memlog-init))
:stopped

;; We memtrace FCAT (like TRACE, MEMTRACE arguments are not evaluated):
;;
cg-user(13): (mp:memtrace fact)
#&lt;Interpreted Function fact&gt;

;; We start memtracing:

cg-user(14): (mp:memlog-start)
:started
cg-user(15): (fact 3)
6

;; Now we examine the data collected. Note the format is different but
;; all the information is there.
;;
cg-user(17): (mp:memlog-show)
    4 Listener 1        35907 fact 1 3 nil nil 
    4 Listener 1        35907 fact 2 2 nil nil 
    4 Listener 1        35907 fact 3 1 nil nil 
    4 Listener 1        35907 fact 4 0 nil nil 
    4 Listener 1        35907 fact -4 1 nil nil 
    4 Listener 1        35907 fact -3 1 nil nil 
    4 Listener 1        35907 fact -2 2 nil nil 
    4 Listener 1        35907 fact -1 6 nil nil 
#S(multiprocessing::memory-log :state :stopped :gate #(549756110504 549756110504 0) :yield-rate 5 :yield t :skipped ...)

;; We run FACT in another process:

cg-user(19): (mp:process-run-function &quot;ftest1&quot; #'fact 3)
#&lt;multiprocessing:process ftest1(5) @ #x2028dea52&gt;

;; MEMLOG-SHOW with no arguments shows all data collected (and still present --
;; when the max size is reached, old data drops out but that has not happened
;; yet):
;;
cg-user(20): (mp:memlog-show)
    4 Listener 1        35907 fact 1 3 nil nil 
    4 Listener 1        35907 fact 2 2 nil nil 
    4 Listener 1        35907 fact 3 1 nil nil 
    4 Listener 1        35907 fact 4 0 nil nil 
    4 Listener 1        35907 fact -4 1 nil nil 
    4 Listener 1        35907 fact -3 1 nil nil 
    4 Listener 1        35907 fact -2 2 nil nil 
    4 Listener 1        35907 fact -1 6 nil nil 
    5 ftest1           146090 fact 1 3 nil nil 
    5 ftest1           146090 fact 2 2 nil nil 
    5 ftest1           146090 fact 3 1 nil nil 
    5 ftest1           146090 fact 4 0 nil nil 
    5 ftest1           146090 fact -4 1 nil nil 
    5 ftest1           146090 fact -3 1 nil nil 
    5 ftest1           146090 fact -2 2 nil nil 
    5 ftest1           146090 fact -1 6 nil nil 
#S(multiprocessing::memory-log :state :stopped :gate #(549756117928 549756117928 0) :yield-rate 5 :yield t :skipped ...)

;; We can restrict what is shown to a specific thread:
;;
cg-user(21): (mp:memlog-show :thread &quot;ftest1&quot;)
    5 ftest1           146090 fact 1 3 nil nil 
    5 ftest1           146090 fact 2 2 nil nil 
    5 ftest1           146090 fact 3 1 nil nil 
    5 ftest1           146090 fact 4 0 nil nil 
    5 ftest1           146090 fact -4 1 nil nil 
    5 ftest1           146090 fact -3 1 nil nil 
    5 ftest1           146090 fact -2 2 nil nil 
    5 ftest1           146090 fact -1 6 nil nil 
#S(multiprocessing::memory-log :state :stopped :gate #(549756161960 549756161960 0) :yield-rate 5 :yield t :skipped ...)

;; We stop memlogging:
cg-user(22): (mp:memlog-stop)
:stopped
cg-user(23): 
</pre>


</body><hr><p id="2"><small>Copyright (c) 1998-2017, Franz Inc. Oakland, CA., USA. All rights reserved.</small><br>
<small>This page was not revised from the 10.0 page.</small><br><small>Created 2017.2.15.</small><br>
</p><table border="0" width="100%" cellpadding="1" cellspacing="0"><tr><td colspan="2" bgcolor="#00FFFF"><table border="0" cellpadding="5" cellspacing="3"><tr><td align="left" bgcolor="#00FFFF"><a href="contents.htm"><b>ToC</b></a></td><td align="left" bgcolor="#00FFFF"><a href="introduction.htm"><b>DocOverview</b></a></td><td align="left" bgcolor="#00FFFF"><a href="cgide.htm"><b>CGDoc</b></a></td><td align="left" bgcolor="#00FFFF"><a href="release-notes.htm"><b>RelNotes</b></a></td><td align="left" bgcolor="#00FFFF"><a href="http://www.franz.com/support/faq/"><b>FAQ</b></a></td><td align="left" bgcolor="#00FFFF"><a href="index.htm"><b>Index</b></a></td><td align="left" bgcolor="#00FFFF"><a href="permuted-index.htm"><b>PermutedIndex</b></a></td></tr></table></td><td align="right"><b>Allegro CL version 10.1</b><br><small><a href="introduction.htm#updates-s">Unrevised from 10.0 to 10.1.</a></small><br><a href="http://www.franz.com/support/documentation/10.0/doc/smp.htm">10.0 version</a></td></tr></table></html>